def get_processed_consensus_input(wildcards):
    if wildcards.read_type == "se":
        return "results/consensus/{}.se.fq".format(wildcards.sample)
    return [
        "results/consensus/{}.1.fq".format(wildcards.sample),
        "results/consensus/{}.2.fq".format(wildcards.sample),
    ]


rule all:  # [hide]
    input:  # [hide]
        "results/consensus/sampleA.merged.bam",  # [hide]


rule bwa_index:
    input:
        "resources/chr21.fa",
    output:
        idx=multiext("resources/chr21.fa", ".amb", ".ann", ".bwt", ".pac", ".sa"),
    log:
        "logs/bwa_index.log",
    resources:
        mem_mb=369000,
    wrapper:
        "master/bio/bwa/index"


rule samtools_sort:
    input:
        "{path}/{sample}.bam",
    output:
        temp("{path}/{sample}.sorted.bam"),
    params:
        extra="-m 4G",
        tmp_dir="/tmp/",
    # Samtools takes additional threads through its option -@
    threads: 8  # This value - 1 will be sent to -@.
    wrapper:
        "master/bio/samtools/sort"


rule calc_consensus_reads:
    input:
        "mapped/{sample}.marked.sorted.bam",
    output:
        consensus_r1=temp("results/consensus/{sample}.1.fq"),
        consensus_r2=temp("results/consensus/{sample}.2.fq"),
        consensus_se=temp("results/consensus/{sample}.se.fq"),
        skipped=temp("results/consensus/{sample}.skipped.bam"),
    params:
        extra="--verbose-read-names",
    log:
        "logs/consensus/{sample}.log",
    wrapper:
        "master/bio/rbt/calc_consensus"


rule map_consensus_reads:
    input:
        reads=get_processed_consensus_input,
        idx=rules.bwa_index.output,
    output:
        temp("results/consensus/{sample}.{read_type}.mapped.bam"),
    params:
        index=lambda w, input: os.path.splitext(input.idx[0])[0],
        sort="samtools",
        sort_order="coordinate",
    wildcard_constraints:
        read_type="pe|se",
    log:
        "logs/bwa_mem/{sample}.{read_type}.consensus.log",
    threads: 8
    wrapper:
        "master/bio/bwa/mem"


rule mark_skipped_duplicates:
    input:
        bams=["results/consensus/{sample}.sorted.bam"],
    output:
        bam=temp("results/consensus/{sample}.marked.bam"),
        metrics="results/consensus/{sample}.metrics.txt",
    log:
        "logs/picard/marked/{sample}.log",
    params:
        extra="--VALIDATION_STRINGENCY LENIENT --TAG_DUPLICATE_SET_MEMBERS true",
    # optional specification of memory usage of the JVM that snakemake will respect with global
    # resource restrictions (https://snakemake.readthedocs.io/en/latest/snakefiles/rules.html#resources)
    # and which can be used to request RAM during cluster job submission as `{resources.mem_mb}`:
    # https://snakemake.readthedocs.io/en/latest/executing/cluster.html#job-properties
    resources:
        mem_mb=1024,
    wrapper:
        "master/bio/picard/markduplicates"


rule merge_consensus_reads:
    input:
        "results/consensus/{sample}.skipped.marked.bam",
        "results/consensus/{sample}.se.mapped.bam",
        "results/consensus/{sample}.pe.mapped.bam",
    output:
        "results/consensus/{sample}.merged.bam",
    log:
        "logs/samtools_merge/{sample}.log",
    threads: 8
    wrapper:
        "master/bio/samtools/merge"
